\chapter{Elementos de ecuaciones diferenciales parciales estocásticas}

En este capítulo hablaremos acerca del concepto de ecuación diferencial parcial estocástica.
Dichos objetos comenzaron a ser estudiados a mediados del siglo pasado con la llegada de la integral de Itô.
El trabajo de Itô y demás colegas para tratar ecuaciones diferenciales estocásticas inmediatamente sugirió el estudio de la posible generalización a ecuaciones diferenciales en varias variables.
Durante las décadas de los 50, 60 y 70, varios artículos hacían alusión a estos objetos, aunque no fue sino hasta finales de la década de 1970 cuando finalmente estas ecuaciones comenzaron a ser estudiadas como objetos matemáticos en sí.
Finalmente, en la década de 1980, varias monografías surgieron con el propósito de construir una teoría que cohesionara las ideas existentes en el área. Destaca en particular la monografía escrita por Walsh \cite{Walsh_J.B_Introduction_to_SPDEs} y publicada en 1986, en donde el autor aborda el estudio de éstas ecuaciones, dando un significado preciso a lo que significa plantear y resolver una ecuación diferencial que involucre procesos estocásticos cuyas trayectorias generalmente no son diferenciables, y que tengan variables tanto espaciales como una temporal.

Desde esta década múltiples trabajos en esta área han sido publicados. Esto, junto con el uso de herramientas como cálculo de Malliavin en el estudio de las mismas, han hecho de las Ecuaciones diferenciales parciales estocásticas una área bastante activa en la probabilidad moderna. 
\section{Introducción a SPDEs}
Comenzamos en este capítulo con la pregunta clave: ¿qué es una ecuación diferencial parcial estocástica? Para responder a esta pregunta, podemos repasar cada uno de los conceptos que nos llevan a esta idea. Partimos del mundo clásico en $\R^{N}:$ sean $x\in \R^{N}$, $t\in [0,\infty)$ y $u:\R^{N}\times[0,\infty)\to \R$ una función en las variables $x$ y $t$. Una ecuación diferencial parcial es una ecuación del tipo 

\begin{equation}\label{ec_dif_parc}
    F(t,x,u,Du,D^2u,...)=0,    
\end{equation}

donde $x$ y $t$ se interpretan como las variables espacial y temporal respectivamente, y $F$ es una función arbitraria que depende tanto de las variables espaciales como de la temporal, así como de la misma función $u$ y de sus derivadas de orden $\alpha=(\alpha_1,...,\alpha_n)$, donde $\alpha_i$ representa la derivada parcial en la $i$-ésima coordenada.

Si existe una función $u$ tal que $u\in C^{\alpha}\left(\R^{N}\times [0,\infty)\right)$ y además $u$ satisface la ecuación \eqref{ec_dif_parc}, donde $\alpha$ es el multi-índice más grande tal que el orden de todas las derivadas que aparecen en la ecuación son cubiertas por el mismo, entonces decimos que $u$ es una solución clásica a la ecuación diferencial parcial anterior. De esta manera, y en particular para la ecuación estocástica del calor homogénea clásica, la cual está dada por 
\[
    \partial_tu(x,t)-\frac{1}{2}\Delta_x u(x,t)=0,
\]
se entiende por solución clásica a una función $u:\R^{N}\times[0,\infty)\to \R$ tal que $u\in C^{2,1}\left(\R^{N}\times [0,\infty)\right)$, esto es, al menos todas las segundas derivadas en las variables espaciales existen y son continuas, y al menos la derivada en la variable temporal existe y es continua. 

Cabe destacar que la noción de solución de un ecuación diferencial parcial en el sentido clásico coincide con lo esperable: una función $u$ será solución de una ecuación diferencial si al menos tiene tantas derivadas como aquellas involucradas en la igualdad \eqref{ec_dif_parc}.

No obstante, en algunas ocasiones los problemas planteados requieren soluciones que no necesariamente cumplan tales características de regularidad, pero que intuitivamente deberían tener sentido.
 Un ejemplo muy conocido es aquél de la ecuación de onda con una condición inicial que no necesariamente es regular. Por ejemplo, si hablamos del problema homogéneo de la ecuación de onda unidimensional dado por:
\begin{equation}\label{wave_eq_sobolev}
    \begin{cases}
        \partial_{tt}u(x,t)-\kappa^2\partial_{xx}u(x,t)=0 & (x,t)\in [-\pi,\pi]\times[0,\infty),\\
        u(-\pi,t)=u(\pi,t)=0, & t\in [0,\infty),\\
        u(x,0)=u_0(x)=\pi-\abs{x} & x\in [-\pi,\pi],\\
        u_t(x,0)=0 & (x,t) \in [-\pi,\pi]\times[0,\infty),\\
    \end{cases}
\end{equation}
es claro que tenemos una inconsistencia al momento de colocar la condición inicial dada por el valor absoluto $\pi-|x|$: dicha función no es derivable en $x=0$. No obstante, desde un punto de vista intuitivo, claramente el problema tiene sentido: estamos modelando el comportamiento de una cuerda sujeta en sus extremos a los puntos $-\pi$ y $\pi$, la cual al soltarla tiene una posición inicial dada por $\pi-|x|$ y cuya velocidad inicial es constante $0$ en cualquier punto de la cuerda.\newline

La idea para hallar una solución al problema anterior a grandes rasgos consiste en reformular el problema de forma que se conserve la esencia del problema, y posteriormente obtener una solución a este problema reformulado. Una manera estándar es utilizar la teoría de distribuciones. En el caso particular de la ecuación de onda anterior, se procede formalmente de la siguiente manera:

Supongamos que $u$ es una solución al problema $\eqref{wave_eq_sobolev}$. En particular se debería cumplir que 
\[
\partial_{tt}u(x,t)=\kappa^2\partial_{xx}u(x,t),
\]
por lo que para cualquier función $\phi\in C^{\infty}_c\left([-\pi,\pi]\times [0,\infty)\right)$ tal que se anule en la frontera,, se tiene que al multiplicar e integrar, la ecuación anterior se convierte en:
\[
    \int_{[-\pi,\pi]\times [0,\infty)}\partial_{tt}u(x,t)\phi(x,t)dx dt=\kappa^2\int_{[-\pi,\pi]\times [0,\infty)}\partial_{xx}u(x,t)\phi(x,t)dx dt,
\]
y suponiendo que es válido utilizar integración por partes, la igualdad anterior equivale a
\[
\int_{[-\pi,\pi]\times [0,\infty)}u(x,t)\partial_{tt}\phi(x,t)dx dt=\kappa^2\int_{[-\pi,\pi]\times [0,\infty)}u(x,t)\partial_{xx}\phi(x,t)dx dt,
\]
en donde los términos evaluados en la frontera se anulan gracias a que las funciones $\phi$ (a menudo denominadas funciones de prueba) se anulan en la misma. Reordenando los términos anteriores, se obtiene una reformulación de la ecuación diferencial del problema \eqref{wave_eq_sobolev} la cual no necesita que la función $u$ sea derivable. A saber, decimos que $u$ es una solución débil de la ecuación diferencial asociada al problema \eqref{wave_eq_sobolev} si se cumple que 
\[
\int_{[-\pi,\pi]\times [0,\infty)}u(x,t)(\partial_{tt}\phi(x,t)-\kappa^2\partial_{xx}\phi(x,t))dx dt=0    
\]
para cualquier función $\phi\in C^{\infty}_c([-\pi,\pi]\times [0,\infty))$ que se anule en la frontera.

Claramente toda solución clásica (o fuerte) es a su vez una solución débil, ya que precisamente la regularidad de dichas soluciones permiten hacer de manera rigurosa los cálculos formales anteriores.
No obstante, la existencia de una solución débil en el sentido anterior no garantiza que dicha solución sea regular, por lo que en principio es más sencillo demostrar la existencia o unicidad de las soluciones débiles, a pesar de que estas gocen de menos propiedades que las soluciones fuertes o clásicas, las cuales no siempre existirán, como en el caso del problema $\eqref{wave_eq_sobolev}$.

Llegados a este punto, reflexionamos ahora en dirección de la probabilidad. Supongamos nuevamente que tenemos la ecuación de onda unidimensional, pero considerando el caso no homogéneo. Tenemos entonces la siguiente ecuación
\begin{equation}\label{wave_spde}
\partial_{tt}u(x,t)=\kappa^2\partial_{xx}u(x,t)+F(x,t), \qquad (x,t)\in [-\pi,\pi]\times[0,\infty)
\end{equation}
donde ahora $F$ es una función que representa la cantidad de presión por unidad de longitud que se aplica a la cuerda. Bajo condiciones de regularidad en la función $F$, podemos resolver el problema de manera clásica utilizando el método de separación de variables. Sin embargo, nos preguntamos ¿qué sucede si ahora $F$ representa una función que no sea diferenciable? Más aún, ¿qué pasa si consideramos a $F$ una \textit{perturbación aleatoria}?

Para dar un sentido más preciso a las ideas anteriores podemos pensar, para $x$ y $t$ fijos, a $F(x,t)$ como una variable aleatoria. Dicha variable depende tanto del espacio como del tiempo, y por ende podemos interpretar a $F$ como un proceso estocástico que evoluciona de manera espacio-temporal. Tal y como se comentó al inicio, es conocido que existen procesos estocásticos cuyas trayectorias son no diferenciables, por lo que en principio pensar en resolver una ecuación diferencial de este estilo de manera clásica se vislumbra una tarea complicada.

Más aún, ¿en qué sentido se debe interpretar una ecuación como \eqref{wave_spde}?, o bien, considerando la siguiente ecuación del calor no homogénea 
\begin{equation}\label{heat_spde}
    \partial_t{u(x,t)}=\frac{1}{2}\Delta_{x}u(x,t)+F(x,t), \qquad (x,t)\in \R^{N}\times[0,\infty),
\end{equation}
en donde el término $F$ sea aleatorio, ¿bajo qué significado hablamos de una solución de dicha ecuación?

Obsérvese que, si bien la teoría de distribuciones nos permite lidiar con la parte de la no regularidad de las condiciones del problema, para replicar el mecanismo que fue utilizado para reformular\eqref{wave_eq_sobolev} en un sentido débil, nos encontramos con una dificultad, ya que a no ser que el proceso $F(x,t)$ sea de variación finita, no será posible realizar de manera rigurosa la transición al momento de integrar por partes.

\subsection{Heurística de la formulación Mild}

Un vistazo más a detalle de lo anterior puede arrojarnos luz sobre cómo sortear el problema. Suponiendo que lo anterior es válido, una manera de proceder con la solución de la ecuación del calor no homogénea será la siguiente. Supongamos que tenemos la siguiente ecuación diferencial del calor unidimensional no lineal:
\[
\partial_tu(x,t)=\frac{1}{2}\partial_{xx}u(x,t)+W(x,t)u(x,t), \qquad (x,t)\in [0,L]\times [0,\infty) 
\]
donde $W(x,t)$ representa nuestra fuente de aleatoriedad (aunque bien puede pensarse como una función suficientemente suave en principio). Utilizando la técnica presentada en el ejemplo de la ecuación de onda, podríamos tomar una función $\phi \in C^{\infty}([0,L])$ cuya derivada se anule en la frontera, multiplicarla por la ecuación anterior e integrar con respecto al espacio y al tiempo, obteniendo que 
\[
\int_{0}^{L}u(x,t)\phi(x)dx-\int_{0}^{L}u(x,0)=\int_{0}^{L}\int_{0}^{t}\partial_{xx}u(x,s)\phi(x)dx ds+\int_{0}^{L}\int_{0}^{t}\partial_{xx}f(x,s)\phi(x)W(dx,ds)
\]
 
Resta entonces estudiar en qué sentido podemos integrar la ecuación \eqref{wave_spde} o \eqref{heat_spde} para sortear las dificultades que la aleatoriedad añade al problema.


\section{Integral de Itô-Walsh}
En esta sección presentamos la construcción de la integral de Itô-Walsh. Dicha integral nos permite construir procesos estocásticas que más adelante y en cierto sentido pueden verse como la solución de una ecuación diferencial parcial estocástica. Para lograr dicho objetivo, presentamos primeramente la teoría necesaria para construir la integral.
\subsection{Variables Gaussianas y Procesos Gaussianos}
Recordamos aquí las propiedades fundamentales de los procesos gaussianos. Salvo algunos casos especiales, la mayoría de las propiedades se enuncian sin demostración, por lo que nos referiremos a \cite{gall2016brownian} para revisar las pruebas de las mismas. Comenzamos definiendo la distribución Gaussiana.

\begin{dfn}
Sea $(\Omega, \F, \P)$ un espacio de probabilidad y consideremos a los reales dotados de la $\sigma-$álgebra de Borel, la cual denotamos por $\B(\R)$. Decimos que una variable aleatoria $X:(\Omega, \F)\to (\R,\B(\R))$ tiene distribución normal estándar (o bien, es una variable Gaussiana estándar), si la función de distribución de la misma está dada por: 
\[
F_X(t)=\int_{-\infty}^{t}\frac{1}{\sqrt{2\pi}}e^{-x^2/2}dx.    
\]
En otras palabras, si la variable aleatoria $X$ tiene densidad (con respecto a la medida de Lebesgue en $\R$) dada por la función 
\[
f_X(t)=\frac{1}{\sqrt{2\pi}}e^{-t^2/2}.
\]
En tal caso, denotamos dicha situación por $X\sim$ Normal(0,1).
\end{dfn}

Directamente de la definición, tenemos la caracterización de la variable Gaussiana en términos de su transformada de Laplace y de su transformada de Fourier.
\begin{prop} 
 Sea $X$ una variable aleatoria con distribución normal estándar. Su transformada de Laplace en todo $\C$ está dada por 
 \[
 \mathcal{L}_X(\lambda):=\E\left[e^{\lambda X}\right]=e^{\lambda^2/2}, \qquad \lambda\in \C,
 \]
mientras que su transformada de Fourier (o función característica) en $\R$ está dada por 
\[
\mathcal{F}_X(\xi):=\E\left[e^{-i\xi X}\right]=e^{-\xi^2/2}, \qquad \xi \in \R. 
\]
 \end{prop}
Se puede ver usando alguna de las transformadas anteriores y usando un argumento inductivo que una variable normal estándar tiene momentos $n$-ésimos de cualquier orden, y que los mismos están dados por 
 \begin{itemize}
   \item $\E\left[X^{2n}\right]=(n-1)!!=\frac{(2n)!}{2^nn!}=1\cdot3\cdot5\cdot_...\cdot (2n-1), \qquad n\geq0$.
   \item $\E\left[X^{2n+1}\right]=0, \qquad n\geq0$.
 \end{itemize}
 En particular, se cumple que $\E\left[X^{n+1}\right]=n\cdot \E\left[X^{n-1}\right]$, para $n\geq1$.

Diremos también que una variable aleatoria Gaussiana tiene media $\mu\in \R$ y varianza $\sigma^2>0$ si se cumple que $Y=\sigma X+\mu$ para $X$ una variable normal estándar. En tal caso, denotaremos la situación por $Y\sim$ Normal$(\mu,\sigma^2)$. En vista de la proposición anterior y de la definición, se tiene la siguiente proposición.
\begin{prop} 
 Sea $Y$ una variable aleatoria normal con media $\mu\in \R$ y varianza $\sigma^2>0$. Entonces las siguientes tres proposiciones son equivalentes a este hecho.
 \begin{itemize}
    \item $\mathcal{L}_Y(\lambda)=e^{\mu\lambda+\sigma^2\lambda^2/2}, \qquad \lambda \in \C,$
    \item $\F_X(\xi)=e^{i\mu\xi-\sigma^2\xi^2/2}, \qquad \xi \in \R$,
    \item La distribución de $Y$ tiene densidad con respecto a la medida de Lebesgue en $\R$ dada por 
    \[
        f_Y(y)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-(y-\mu)/2\sigma^2}, \qquad t\in \R.    
    \]
 \end{itemize}
 \end{prop}
 Por convención, diremos que una variable $Y$ tiene distribución normal con media $\mu\in \R$ y varianza $\sigma^2=0$ (denotado por $Y\sim$ Normal$(\mu,0)$) si se cumple que $Y=\mu$, \  $\lambda$-casi seguramente, donde $\lambda$ denota la medida de Lebesgue en $\R$.

 Pasamos ahora a definir los vectores Gaussianos o vectores normales conjuntos. 
 \begin{dfn} 
  Sea $(\R^d, \langle\cdot,\cdot\rangle)$ el espacio $\R^{d}$ dotado de su producto interno usual. Decimos que una variable aleatoria $X:(\Omega,\F)\to (\R^{d},\B(\R^d))$ es un vector gaussiano, o un vector normal conjunto, si para cualquier $u\in \R^d$, se tiene que $\langle u,X\rangle$ es una variable aleatoria Gaussiana (en $\R$).
  \end{dfn}
Presentamos un primer resultado sobre vectores aleatorios Gaussianos.
\begin{prop} 
Sea $X$ un vector aleatorio Gaussiano en $\R^{d}$. Entonces existe una función $\mu_X\in\R^d$ y una forma cuadrática no negativa $q_X:\R^d\to \R$ tales que para cualquier $u\in \R^d$,
\begin{itemize}
    \item $\E\left[\langle u,X\rangle\right]=\langle u,\mu_X\rangle$
    \item $\text{Var}\left(\langle u,X\rangle\right)=q_X(u)$.
\end{itemize}
De hecho, si tenemos una base ortonormal $(e_{j})_{j\geq1}$ de $\R^{d}$, entonces podemos escribir a $X$ de la siguiente manera:
\[
X=\sum_{j=1}^{d}\langle X,e_j\rangle e_j,  
\]
donde $X_j:=\langle X,e_j\rangle$, por definición, es una variable aleatoria Gaussiana, para cualquier $j\geq1$. De lo anterior, se sigue que, escribiendo $u\in \R^d$ como $u=\sum_{j=1}^{d}u_je_j$, se tiene que 
\begin{itemize}
    \item $\mu_X=\E\left[X_j\right]e_j$.
    \item $q_X(u)=\sum_{j=1}^{d}\sum_{i=1}^{d}u_iu_j \text{Cov}\left(X_i,X_j\right)$.
\end{itemize}
 \end{prop}

Se sigue de la proposición anterior la fórmula de la función característica de un vector gaussiano.
\begin{prop} 
 Sea $X$ un vector aleatorio gaussiano y $(e_j)_{j\geq1}$ una base ortonormal de $\R^{d}$. Entonces, al ser $\langle u,X\rangle\sim$ Normal$(\langle u,\mu_X\rangle,q_X(u))$, se tiene que %Si denotamos por $\E\left[X\right]:=\sum_{j=1}^{d}\E\left[X_j\right]e_j$, entonces 
 \[
 \E\left[e^{i\langle u,X\rangle}\right]=e^{i \langle u,\mu_X\rangle-\frac{1}{2}q_X(u)}, \qquad u\in \R^d.
 \]
 \end{prop}
Y en vista de las dos proposiciones anteriores, está la siguiente caracterización de variables aleatorias Gaussianas independientes.
\begin{prop} 
 Sea $X$ un vector aleatorio gaussiano en $\R^{d}$, y sea $(e_j)_{j\geq1}$ una base ortonormal de $\R^{d}$. Entonces $X_1,...,X_d$ son variables aleatorias independientes si y solo sí la matriz de covarianzas $\Sigma=(\text{Cov}\left(X_i,X_j\right))_{1\leq i,j\leq d}$ es diagonal. Equivalentemente, $X_1,...,X_d$ son independientes si y solo si la forma cuadrática $q_X$ está en forma diagonal en la base $(e_j)_{j\geq1}$.
 \end{prop}

 Pasamos ahora a estudiar procesos estocásticos formados por variables aleatorias gaussianas.
\begin{dfn} 
 Sea $T$ un conjunto arbitrario y sea $G=(G(t))_{t\in T}$ una colección de variables aleatorias indexadas por $T$. Decimos que $G$ es un proceso Gaussiano, o un campo aleatorio Gaussiano si para cualesquiera $t_1,...,t_k\in T$, se tiene que $X=(G(t_1),...,G(t_k))$ es un vector gaussiano, $k\geq1$. 
\end{dfn}

Equivalentemente, un proceso estocástico $(G(t))_{t\in T}$ es Gaussiano si cualquier combinación lineal finita de variables $G(t)$, $t\in T$ es Gaussiana, lo cual de acuerdo a nuestra exposición, también equivale a decir que las distribuciones finito-dimensionales de un proceso Gaussiano $(G(t))_{t\in T}$ están dictadas por medio de variables aleatorias gaussianas.

A menudo es importante saber cuando un proceso gaussiano es independiente de otro proceso gaussiano. Para ello, recordamos la definición de $\sigma$-álgebra generada por un conjunto de variables.

\begin{dfn} 
 Sea $H$ una familia de variables aleatorias definidas en un espacio de probabilidad $(\Omega, \F, \P)$. La $\sigma$-álgebra generada por $H$ es la $\sigma$-álgebra más pequeña en $\Omega$ tal que todas las variables $X\in H$ son medibles con respecto a dicha $\sigma$-álgebra. A tal estructura la denotamos como $\sigma(H)$.  
 \end{dfn}
Enunciamos ahora un importante resultado con respecto a la independencia de dos conjuntos de variables aleatorias gaussianas. Este resultado nos dice que, en cierto sentido, dos conjuntos de variables aleatorias Gaussianas son ortogonales si y solo si son independientes entre sí. 

\begin{prop}\label{Gaussi_indep} 
 Sean $G_1$, $G_2$ dos familias de variables aleatorias Gaussianas centradas (i.e. con media cero). Denotemos por $H_1$ y $H_2$ al subespacio lineal cerrado de $L^{2}(\P)$ generado por dichas variables. Entonces dichos espacios están formados por variables aleatorias Gaussianas centradas.

 Más aún, son equivalentes 
 \begin{itemize}
    \item Los subespacios $H_1$ y $H_2$ son ortogonales entre sí en $L^{2}(\P)$.
    \item Las $\sigma$-álgebras $\sigma(H_1)$ y $\sigma(H_2)$ son independientes.
 \end{itemize}
 Es importante recordar que esta propiedad es muy particular del contexto Gaussiano.
 \end{prop}
Ahora bien, dado un proceso Gaussiano $G$, tenemos dos funciones asociadas al mismo.
\begin{dfn} 
 Sea $G=(G(t))_{t\in T}$ un proceso gaussiano. Definimos las funciones de media y covarianza del proceso $G$ respectivamente como sigue.
 \begin{enumerate}
    \item $\mu(t):=\E\left[G(t)\right]$, \qquad para cualquier $t\in T$,
    \item $\Gamma(s,t):= \text{Cov}\left(G(s),G(t)\right)$, \qquad para cualesquiera $s,t\in T$.
 \end{enumerate}
 \end{dfn}
Dichas funciones con valores en $\R$ determina la colección de distribuciones finito-dimensionales del proceso. 
De hecho, gracias a las proposiciones anteriores es claro que para cualesquiera subíndices $(t_1,...,t_k)\subseteq T$, la ley del vector Gaussiano $X=(G(t_1),...,G(t_k))$ está determinada de manera única. 

Lo anterior pues $\mu_X:=(\E\left[G(t_1)\right],...,\E\left[G(t_k)\right])=(\mu(t_1),...,\mu(t_k))$ y $q_X$ la forma cuadrática asociada que está determinada por la matriz de covarianzas de $X$, está en términos de la función $\Gamma$ definida antes, a saber, $\Sigma_X=\left(\text{Cov}\left(G(t_i),G(t_j)\right)\right)_{1\leq i,j\le k}=\left(\Gamma(t_i,t_j)\right)_{1\le i,j\le k }$.

Es consecuencia de que la forma cuadrática $q_X$ para cualquier vector $X$ que componga una distribución finito-dimensional de $G$, sea no negativa definida y simétrica, el hecho de que la función de covarianzas $\Gamma$ sea no negativa definida. A saber, si $c:T\to \R$ es una función con soporte finito, entonces 
\[  
    \sum_{T\times T}^{}c(s)c(t)\Gamma(s,t)\geq0
\]
Lo valioso de conocer las funciones anteriores es que, al caracterizar completamente las distribuciones finito-dimensionales del proceso Gaussiano $G$, todo el proceso está caracterizado por medio de dichas funciones, por lo que basta conocer dichas funciones para construir un proceso Gaussiano. Este es el contenido del siguiente teorema.

\begin{prop} 
 Sean $\Gamma:T\times T\to \R$ y $\mu:T\to \R$, tales que $\Gamma$ es simétrica y no negativa definida. Entonces existe un proceso gaussiano $(G(t))_{t\in T}$ en un espacio de probabilidad $(\Omega, \F,\P)$ apropiado, tal que para cualesquiera $t\in T$, $G(t)\sim$ Normal$(\mu(t),\Gamma(t,t))$, con $\mu$ y $\Gamma$ las respectivas funciones de media y covarianza del proceso $G$.
 \end{prop}
 La demostración de lo anterior es una consecuencia del Teorema de Consistencia (o extensión) de Kolmogorov (ver Teorema 6.3 en \cite{gall2016brownian} ). Para terminar esta sección, a continuación presentamos un par de ejemplos de procesos Gaussianos construidos de esta forma.
\begin{ejem}[\textbf{El movimiento Browniano}]
Consideremos el caso en el que $T=[0,\infty)$, $\mu(t)=0$ para cualquier $t\geq0$ y $\Gamma(s,t)=s\wedge t=\min\{s,t\}$, para $s,t\geq0$. Claramente $\Gamma$ es simétrica, y además nótese que para cualesquiera $c:T\to\R$ función de soporte finito, se tiene que
\begin{align*}
\sum_{T\times T}^{}c(s)c(t)\Gamma(s,t)&=\sum_{s\in T}^{}\sum_{t\in T}c(s)c(t)(s\wedge t)\\
&=\sum_{s\in T}^{}\sum_{t\in T}c(s)c(t)\int_{0}^{\infty}\1_{[0,s]}(x)\1_{[0,t]}(x)dx\\
&=\int_{0}^{\infty}\sum_{s\in T}\sum_{t\in T}\1_{[0,s]}(x)c(s)\1_{[0,t]}(x)c(t)dx\\
&=\int_{0}^{\infty}\abs{\sum_{t\in T}\1_{[0,t]}(x)c(t)}^2dx\\
&\geq0,
\end{align*}
por lo que por la proposición anterior, existe en un espacio de probabilidad adecuado un proceso gaussiano que denotaremos por $(B(t))_{t\geq0}$, con función de medias 0 y función de covarianza $\Gamma(s,t)=s\wedge t$. Dicho proceso es el movimiento Browniano estándar.
 \end{ejem}
El siguiente ejemplo es de suma importancia y es parte esencial en el resto del texto.

\begin{ejem}[\textbf{El ruido blanco en $\R^{d}$}] 
Sea $T=\B(\R^{d})$ el conjunto de los borelianos en $\R^d$.
Dado que estamos hablando de subconjuntos de $\R^{d}$, cambiaremos la notación al indicar con letras mayúsculas a los elementos de $T$.
Consideremos nuevamente la función de medias $\mu(A):=0$, para cualquier $A\in \B(\R^{d})$ y ahora consideremos la función $\Gamma(A,B):=\lambda^{d}(A\cap B)$, donde $\lambda^{d}:\B(\R^{d})\to [0,1]$ es la medida de Lebesgue en $\R^{d}$.

 Claramente $\Gamma$ es una función simétrica, y además, para $c:T\to\R$ función de soporte finito, se tiene que 
 \begin{align*}
    \sum_{T\times T}^{}c(A)c(B)\Gamma(A,B)&=\sum_{A\in T}^{}\sum_{B\in T}c(A)c(B)\lambda^{d}(A\cap B)\\
    &=\sum_{A\in T}^{}\sum_{B\in T}c(A)c(B)\int_{\R^d}\1_{A}(x)\1_{B}(x)\lambda^{d}(dx)\\
    &=\int_{\R^{d}}\sum_{A\in T}\sum_{B\in T}\1_{A}(x)c(A)\1_{B}(x)c(B)\lambda^{d}(dx)\\
    &=\int_{\R^{d}}\abs{\sum_{A\in T}\1_{A}(x)c(A)}^2\lambda^{d}(dx)\\
    &\geq0,
    \end{align*}
por lo que existe un proceso Gaussiano que denotaremos por $(\dot{W}(A))_{A\in \B(\R^{d})}$ en un espacio de probabilidad adecuado, tal que su función de medias es $0$ y su función de covarianzas es $\Gamma(A,B)=\lambda^{d}(A\cap B)$. Dicho proceso estocástico es conocido como \textit{ruido blanco} en $\R^{d}$.

Observemos que, si $A\cap B=\varnothing$, entonces $\Gamma(A,B)=\text{Cov}\left(\W(A),\W(B)\right)=0$, por lo que al ser variables Gaussianas, estas son independientes según lo visto antes.

Se sigue que si $A,B\in \B(\R^d)$, entonces aprovechando que el proceso es Gaussiano centrado, tenemos que
\begin{align*}
    &\text{Cov}\left(\W(A\cup B)-\W(A)-\W(B)+\W(A\cap B),\W(A\cup B)-\W(A)-\W(B)+\W(A\cap B)\right)\\
    &=\text{Cov}\left(\W(A\cup B),\W(A\cup B)\right)+\text{Cov}\left(\W(A),\W(A)\right)+\text{Cov}\left(\W(B),\W(B)\right)\\
    &\quad +\text{Cov}\left(\W(A\cap B),\W(A\cap B)\right)-2 \text{Cov}\left(\W(A\cup B),\W(A)\right)-2 \text{Cov}\left(\W(A\cup B), \W(B)\right)\\
    &\quad +2 \text{Cov}\left(\W(A\cup B), \W(A\cap B)\right)+2 \text{Cov}\left(\W(A),\W(B)\right)-2 \text{Cov}\left(\W(A),\W(A\cap B)\right)\\
    &\quad -2 \text{Cov}\left(\W(B),\W(A\cap B)\right)\\
    &=\lambda^{d}(A\cup B)+\lambda^{d}(A)+\lambda^{d}(B)+\lambda^{d}(A\cap B)-2\lambda^{d}((A\cup B)\cap A)-2\lambda^{d}((A\cup B)\cap B)\\
    &\quad+2\lambda^{d}((A\cup B)\cap (A\cap B))+2\lambda^{d}(A\cap B)-2\lambda^{d}(A\cap (A\cap B))-2\lambda(B\cap(A\cap B))\\
    &=\lambda^{d}(A\cup B)+\lambda^d(A)+\lambda^{d}(B)+\lambda^{d}(A\cap B)-2\lambda^{d}(A)-2\lambda^{d}(B)+2\lambda^{d}(A\cap B)\\
    &\quad +2\lambda^{d}(A\cap B)-2\lambda^{d}(A\cap B)-2\lambda^{d}(A\cap B)\\
    &=\lambda^{d}(A\cup B)-\lambda^d(A)-\lambda^{d}(B)+\lambda^{d}(A\cap B)\\
    &=\lambda^{d}(A\cup B)-\lambda^{d}(A\cup B)\\
    &=0.
\end{align*}

por lo que la variable $\W(A\cup B)-(\W(A)+\W(B)-\W(A\cap B))$ tiene varianza cero. Luego,
\begin{equation}\label{Wdotmeasure}    
    \W(A\cup B)=\W(A)+\W(B)-\W(A\cap B) \qquad \P-\text{casi seguramente}.
\end{equation}


\end{ejem}
Lo anterior nos podría hacer pensar que el ruido blanco es una medida signada. Sin embargo, esto es falso (ver ejemplo 3.16 de \cite{Khoshnevisan2009}). No obstante, podemos utilizar dicho proceso como base para construir una integral.

\begin{ejem}[\textbf{El proceso isonormal}] 
Dado un ruido blanco $\left(\W(A)\right)_{A\in \B(\R^d)}$, nos gustaría definir $\W(h)$ para alguna función $h$ adecuada. Es bien conocido en teoría de la medida un mecanismo estándar para definir nuevos objetos a partir de objetos más sencillos, y luego extender por aproximación. Seguiremos esta maquinaria estándar a continuación.

Sea $A\in \B(\R^d)$. Definimos $\W(\1_A):=\W(A)$, y para cualesquiera $A_1,...,A_n\in \B(\R^{d})$ disjuntos, y constantes $c_1,...,c_n\in \R$,  definimos
\[
\W \left(\sum_{k=1}^{n}c_k\1_{A_k}\right):=\sum_{k=1}^{n}c_k\W(A_k)    
\]
Nótese que si existen dos representaciones distintas de una función simple, de acuerdo a \eqref{Wdotmeasure}, la variable de la definición anterior es consistente ya que habrá una igualdad $\P-$ casi seguramente. Por otro lado, dado que los conjuntos $A_1,...,A_n$ son disjuntos, las variables $\W(A_1),...,\W(A_n)$ son independientes entre sí. Luego, observamos que al ser centradas,
\begin{align*}
    \norm{\W \left(\sum_{k=1}^{n}c_k\1_{A_k}\right)}_{L^{2}(\P)}^2&=\text{Var}\left(\sum_{k=1}^{n}c_k\W(A_k)\right)\\
    &=\sum_{k=1}^{n}c_k^2 \E\left[\W^2(A_k)\right]\\
    &=\sum_{k=1}^{n}c_k^2 \Gamma(A_k,A_k)\\
    &=\sum_{k=1}^{n}c_k^2\lambda^{d}(A_k)\\
    &=\int_{\R^d}\sum_{k=1}^{n}c_k^2\1_{A_k}\lambda^d(dx)\\
    &=\norm{\sum_{k=1}^{n}c_k\1_{A_k}}^2_{L^{2}(\R^{d})},
\end{align*}
donde en la última igualdad utilizamos que, al ser $A_i\cap A_j=\varnothing$, se tiene que $\1_{A_i}\1_{A_j}=0$ para $i\neq j$. De lo anterior deducimos que la aplicación $f\longmapsto \W(f)$, que envía funciones simples en variables Gaussianas, preserva la norma de los respectivos espacios.

Es un resultado conocido en teoría de la medida que, si tenemos ahora una función $f\in L^{2}(\R^{d})$, existe una sucesión de variables aleatorias simples en $L^{2}(\R^d)$ tales que $f_n\to f$ en la norma de dicho espacio. Luego, la sucesión $(f_n)_{n\ge 1}$ forma una sucesión de Cauchy de funciones simples en $L^2(\R^{d})$. Dado que la norma se preserva para estas funciones entre los espacios $L^2$ según lo visto antes, la sucesión de variables $(\W(f_n))_{n\ge 1}$ es de Cauchy en $L^{2}(\P)$, por lo que al ser un espacio completo, existe una única variable en $L^{2}(\P)$, que denotaremos por $\W(f)$, tal que $\W(f_n)\longrightarrow \W(f)$ en norma $L^{2}(\P)$.

Consideramos así al espacio $L^{2}(\R^{d})$, y a la colección de variables aleatorias $(\W(f))_{f\in L^{2}(\R^{d})}$. A dicho proceso estocástico se le conoce como el \textit{proceso isonormal}. Una característica fundamental de dicho proceso es que la aplicación $A\mapsto\W(A)$ es una isometría, conocida como \textit{isometría de Wiener}. Al elemento $\W(f)$ para $f\in L^2(\R^{d})$ se le conoce como \textit{integral de Wiener de f}, y a menudo se denota como
\[
\W(f)=\int f W(dx).    
\] 
El proceso isonormal se puede también obtener vía su función de medias y su función de covarianzas. En efecto, tomando $T=L^{2}(\R^{d})$, haciendo nuevamente $\mu(f)=0$ para cualquier $f\in L^2(\R)$, y definiendo la función de covarianzas $\Gamma$ como
\[
\Gamma(f,g)=\int_{\R^d}fg \lambda^d(dx)=\langle f,g\rangle_{L^{2}(\R^{d})}, \qquad f,g\in L^2(\R^{d}),
\]
entonces el proceso Gaussiano resultante, que denotamos por $(\W(f))_{f\in L^{2}(\R^{d})}$ es el proceso isonormal que construimos antes vía un ruido blanco. 
 \end{ejem}

\subsection{Medidas martingala}

En esta parte del texto, estudiamos el concepto de medidas martingala. Dichos procesos estocásticos son una pierda angular en la construcción de la integral de Itô-Walsh, como veremos a continuación.

Recordemos que si tenemos un ruido blanco $(W(A))_{A\in \B(R^{d})}$, entonces para cualesquiera $A,B \in \B(\R^{d})$, se tiene la siguiente igualdad
\[
\W(A\cup B)=\W(A)+\W(B)-\W(A\cap B), \qquad \P-\text{casi seguramente.}   
\]
Sin embargo, como también se mencionó en la subsección pasada, a pesar de que esto nos puede hacer pensar en que el ruido blanco constituye una medida aleatoria signada, lo anterior es falso. No obstante, se tiene el siguiente resulado con respecto al mismo.
\begin{prop}\label{Finito_aditiv_ruido_blanco}
 El proceso $(\W(A))_{A\in \R^{d}}$ cumple las siguientes propiedades
 \begin{itemize}
    \item $\W(\varnothing)=0$, \qquad $\P-\text{casi seguramente,}$
    \item Para cualquier sucesión de conjuntos ajenos $(A_n)_{n\geq 1}\subseteq \B(\R^d)$, se cumple que 
    \[
    \W \left(\bigcup_{k=1}^\infty A_k\right)=\sum_{k=1}^{\infty}\W(A_k), \qquad \P-\text{casi seguramente,} 
    \]
 \end{itemize}
 en donde la suma infinita anterior converge en $L^2(\P)$. En otras palabras, el 
 ruido blanco es una medida signada, $\sigma$-finita, $L^2(\P)$-valuada.
\end{prop}
\begin{proof} 
   Es un resultado conocido de teoría de la medida que, si queremos probar que la aplicación anterior es una medida signada, y ya hemos probado que es finito-aditiva, entonces basta con tomarnos una sucesión decreciente de conjuntos $(A_n)_{n\geq1}\subseteq\B(\R^{d})$ tal que al intersecar todos los elementos obtengamos el conjunto vacío, y probar que $\W(A_n)\to 0$ en $L^{2}(\P)$ para concluir.

   En efecto, sea $(A_n)_{n\geq1}$ una sucesión como la descrita antes. Directamente por definición del ruido blanco, 
   \[
   \norm{\W(A_n)}_{L^2(\P)}^2=\E\left[\W^2(A_n)\right]=\Gamma(A_n,A_n)=\lambda^{d}(A_n)\xrightarrow[n\to\infty]{}0,    
   \]
   ya que al ser $\lambda^d$ una medida, se cumple la propiedad de continuidad con la sucesión $(A_n)_{n\geq1}$.

   Para concluir que la medida es $\sigma-$finita, dado que $\R^{d}$ puede ser cubierto con una sucesión numerable de conjuntos compactos, basta ver que para cualquier conjunto compacto $K\subseteq\R^{d}$, se tiene que $\norm{\W(K)}_{L^ {2}(\R^{d})}^2<\infty$. Pero esto es claro, ya que 
   \[
       \norm{\W(K)}_{L^ {2}(\R^{d})}^2=\E\left[\W^2(K)\right]=\lambda^{d}(K)<\infty,
   \]
   ya que los compactos son acotados en $\R^{d}$.
 \end{proof}  
 \begin{obs}
   Es importante distinguir el que el ruido blanco forme una medida $L^{2}(\P)$-valuada a que forme una medida signada aleatoria en los borelianos de $\R^d$. Esto es, nótese que la segunda propiedad de la proposición posee el cuantificador fuera del conjunto de probabilidad 1. Más específicamente, la proposición anterior \textit{no} está asegurando que 
   \[
   \P\left(\left\{\forall \ (A_n)_{n\geq1}\subseteq\B(\R^{d}), \ \ \W \left(\bigcup_{k=1}^\infty A_k\right)=\sum_{k=1}^{\infty}\W(A_k)\right\}\right)=1  
   \]
\end{obs}
Ahora, a menudo es posible considerar una dimensión como la dimensión temporal, de forma que se puede estudiar un ruido blanco definido en el espacio $[0,\infty)\times\R^{d}$. El hecho de pensar al intervalo $[0,\infty)$ como una dimensión temporal nos permite definir un nuevo proceso conocido como el \textit{proceso de ruido blanco}, $(W_t)_{t\geq0}$, definido como 
\[
W_t(A):=\W \left([0,t]\times A\right), \qquad A\in \B(\R^{d}).    
\]
Este es un proceso estocástico que 'evoluciona en el tiempo', pero a su vez, es un ruido blanco en $A$. Recordemos también que la noción de filtración como sucesión de $\sigma$-álgebras ordenadas con respecto a la contención concreta la idea de proceso que evoluciona en el tiempo. Definimos entonces la filtración del proceso de ruido blanco como sigue
\[
\F_t:=\sigma \left(\W([0,t]\times A):0\leq s\leq t, A\in \B(\R^{d})\right), \qquad t\geq0.    
\]
Claramente la familia $(\F_t)_{t\geq0}$ forma una filtración, y además el proceso $(W_t)_{t\geq0}$ es adaptado a dicha filtración.

Una propiedad muy interesante que posee el proceso $(W_t)_{t\geq0}$, visto como un proceso que evoluciona en el tiempo, es que es una medida aleatoria (en el sentido visto antes), y también una martingala. 

\begin{prop} 
Sea $(W_t(A))_{t\geq0, A\in \B(\R)}$ un ruido blanco en $[0,\infty)\times \R^{d}$. Entonces dicho proceso forma una 'medida martingala' en el siguiente sentido:
\begin{itemize}
   \item Para cualquier $A\in \B(\R^{d})$, se cumple $W_0(A)=0, \ \P-$casi seguramente.
   \item Si $t>0$, entonces $W_t$ es una medida signada $\sigma$-finita, $L^{2}(\P)$-valuada.
   \item Para cualquier $A\in \R^{d}$, el proceso $(W_t(A))_{t\geq0, A\in \B(\R)}$ es una martingala de media cero.
\end{itemize}
\end{prop}
\begin{proof} 
 Nótese que por definición, $W_0(A)=\W(\{0\}\times A)$, y dicha variable es tal que 
 \[
 \E\left[\W^2(\{0\}\times A)\right]=\Gamma(0\times A,0\times A)=\lambda{0}\cdot\lambda^{d}(A)=0,  
 \]
 por lo que dicha variable aleatoria es la variable 0 con probabilidad 1.

 Por otro lado, para $t>0$, el que $W_t:\B(\R^{d})\to L^{2}(\P)$ sea una medida signada $\sigma$-finita se sigue de la propiedad siguiente: para cualquier $A\in \B(\R^{d})$, 
 \[
 \E\left[\W([0,t]\times A)\right]=\Gamma([0,t]\times A, [0,t]\times A)=\lambda([0,t])\cdot\lambda^{d}(A)=t\lambda^{d}(A). 
 \] 
 Por lo tanto, si $A=\varnothing$, claramente $\W_t(\varnothing)=0$ con probabilidad 1, ya que $\Gamma([0,t]\times\varnothing,[0,t]\times \varnothing)=0$. Ahora, para mostrar la $\sigma$-aditividad y la $\sigma$-finitud se procede de manera análoga a lo hecho en la proposición \ref{Finito_aditiv_ruido_blanco}: primero, se prueba que la aplicación $W_t:\B(\R)\to L^{2}(\P)$ es finito aditiva, y posteriormente se generaliza. Para la parte de la $\sigma$-finitud se procede igual.

 Finalmente, para mostrar que para cualquier $A\in \B(\R^{d})$ el proceso $t\to W_t(A)$ es una martingala con respecto a la filtración $(\F_t)_{t\geq0}$, observamos que el proceso claramente es integrable (lo componen variables Gaussianas) y es adaptado a la filtración por definición. Resta probar que para $A\in \B(\R)$ fijo,
 \[
 \E\left[W_{s+t}(A)\lvert \F_t\right]=W_t(A), \qquad s,t\geq0  
 \]
 Para ello haremos uso de la proposición \ref{Gaussi_indep}. Consideramos a la familia de variables aleatorias $C_1=\left\{W_u(A):u\leq t\right\}$ y
 $C_2=\left\{W_{t+s}-W_t(A):s>0 \right\}$, para $t\geq0$. Notemos que para $0\le u\le t$,
 \begin{align*}
   \E\left[(W_{t+s}(A)-W_t(A))W_u(A)\right]&=\Gamma([0,t+s]\times A, [0,u]\times A)-\Gamma([0,t]\times A,[0,u]\times A)\\
   &=\lambda([0,t+s]\cap[0,u])\cdot\lambda^{d}(A)-\lambda([0,t]\cap[0,u])\cdot\lambda^{d}(A)\\
   &=\lambda([0,u])\cdot\lambda^{d}(A)-\lambda([0,u])\cdot\lambda^{d}(A)\\
   &=0.
 \end{align*}
 Por lo tanto, para cualesquiera dos variables $\xi_1$ y $\xi_2$ en $C_1$ y $C_2$ respectivamente, se tiene que $\langle \xi_1,\xi_2\rangle_{L^2(\P)}= \E\left[\xi_1\xi_2\right]=0$, esto es, son ortogonales. Por lo tanto, si $H_1$ y $H_2$ representan la cerradura del subespacio lineal generado por las familias $C_1$ y $C_2$ respectivamente, dichos subespacios son ortogonales.
 
 Por lo tanto, por la proposición mencionada antes, las $\sigma$-álgebras generadas por las familias $C_1$ y $C_2$ son independientes. En particular, para $s,t\geq0$, $\F_t\subseteq \sigma(C_1)$, por lo que al ser $W_{t+s}-W(t)$ una variable $\sigma(C_2)$ medible, se sigue que 
 \[
     \E\left[W_{t+s}(A)|\F_t\right]=\E\left[W_{t+s}(A)-W_{t}(A)+W_t(A)|\F_t\right]=\E\left[W_{t+s}(A)-W_t(A)\right]+W_t(A)=W_t(A),
     \]
     por lo que la propiedad de martingala se satisface.  
\end{proof}

El proceso de ruido blanco es entonces un ejemplo de medida martingala, no obstante, este concepto se puede definir de manera mucho más general, como vemos a continuación.

\begin{dfn} 
Sea $(\F_t)_{t\geq0}$ una sucesión de $\sigma$-álgebras continuas por derecha. Un proceso $(M_t(A))_{t\geq0, A\in \B(\R^{d})}$ es una medida martingala con respecto a dicha filtración si 
\begin{itemize}
   \item $M_0(A)=0$ $\P$- casi seguramente.
   \item Si $t>0$, entonces $M_t$ es una medida signada, $\sigma$-finita, $L^{2}(\P)$-valuada.
   \item Para cualquier $A\in \B(\R^{d})$, se tiene que $(M_t(A))_{t\geq0}$ es una martingala con respecto a la filtración $(\F_t)_{t\geq0}$ de media 0.
\end{itemize}
\end{dfn}
Por construcción, el proceso del ruido blanco es un primer ejemplo de medida martingala. La razón de introducir este concepto, es que este conjunto de procesos forman una clase adecuada de integradores. A continuación, definimos un concepto relacionado íntimamente con las medidas martingala, y que es en cierto sentido una generalización del proceso de covariación para dos martingalas en el caso unidimensional.

\begin{dfn} 
 Sea $M$ una medida martingala. El funcional de covarianza de $M$ se define como
 \[
 \overline{Q}_t(A,B):= \langle M_\cdot(A),M_\cdot (B)\rangle_t, \qquad t\geq 0, A, B \in \B(\R^{d}). 
 \]
 \end{dfn}
 Dado que para $M$ una medida martingala, si $A$ y $B \in \B(\R^{d})$ se tiene que $(M_t(A))_{t\geq0}$ y $(M_t(B))_{t\geq0}$ son martingalas, entonces el proceso de covariación de ambas martingalas evaluado en $t\geq0$ coincide con el funcional de covarianza evaluado en los borelianos $A$ y $B$, y en $t\geq0$.

 Gracias a lo anterior, se deducen directamente de las propiedades de la covariación entre dos martingalas las siguientes propiedades del funcional de covarianza de una medida martingala.

 \begin{prop} 
  Sea $M$ una medida martingala y denotemos por $\overline{Q}$ a su funcional de covarianza. Entonces $\overline{Q}$ cumple que
  \begin{itemize}
   \item $\overline{Q}_t(A,B)=\overline{Q}_t(B,A)$, \ $\P$- casi seguramente.
   \item Si $B\cap C=\varnothing$, entonces $\overline{Q}_t(A,B\cup C)=\overline{Q}_t(A,B)+\overline{Q}_t(A,C)$, \ $\P$- casi seguramente.
   \item $\abs{\overline{Q}_t(A,B)}^2\leq \overline{Q}_t(A,A)\overline{Q}_t(B,B)$ \ $\P$-casi seguramente, y 
   \item $t\mapsto\overline{Q}_t(A,A)$ es $\P$- casi seguramente no decreciente.
  \end{itemize}
  \end{prop}

Con el concepto de funcional de covarianza, podemos definir una función aleatoria de conjuntos en $\B(\R^{d})\times \B(\R^{d})\times \B([0,\infty))$, que denotaremos $Q$, como sigue:
\[
   Q(A\times B\times(s,t]):=\overline{Q}_t(A,B)-\overline{Q}_s(A,B), \qquad A,B\in \B(\R^{d}), \ t\geq s\geq 0
   \]
Y extendemos dicha función a uniones disjuntas de elementos (rectángulos)
$(A_i\times B_i\times(s_i,t_i])$ para $1\leq i \leq m$ y $A_i,B_i\in \B(\R^{d})$, $(s_i,t_i]\in \B(\R^{d})$ como 
\[
Q \left(\bigcup_{i=1}^{n}(A_i\times B_i\times(s_i,t_i])\right):=\sum_{i=1}^{n}Q(A_i\times B_i\times (s_i,t_i]).
\]
  
Nuestro objetivo es extender la función aleatoria de conjuntos $Q$ a conjuntos más generales. El problema es que en general no es posible hacerlo. No obstante, con estas dos herramientas teóricas, podemos definir el concepto de \textit{worthiness} de una medida martingala, introducido por Walsh en $\cite{Walsh_J.B_Introduction_to_SPDEs}$.
Dicho concepto es de carácter técnico, pero será fundamental en la construcción de la integral de Itô-Walsh al permitirnos extender la definición de $Q$ a conjuntos más generales.


\begin{dfn} 
Sea $M$ una medida martingala. Decimos que $M$ es \textit{worthy} (digna) si existe una medida $\sigma$-finita $K:\B(\R^{d})\times \B(\R^{d})\times \B([0,\infty))\times \Omega \to [0,1]$ tal que para cualesquiera $A,B\in \B(\R^{d})$, $C\in \B([0,\infty))$ y $\omega \in \Omega$, 
\begin{itemize}
   \item $A\times B\mapsto K(A\times B \times C,\omega)$ es no negativa definida y simétrica,
   \item $\{K(A\times B \times (0,t])\}_{t\geq0}$ es un proceso predecible para cualesquiera $A, B \in \B(\R^{d})$,
   \item Para cualesquiera dos conjuntos compactos $A,B \in \B(R^{d})$, y $t>0$, 
   \[
   \E\left[K(A\times B \times (0,t])\right]<\infty,    
   \]
   \item Para cualesquiera $A,B\in \B(\R^{d})$ y $t>0$,
   \[
   \abs{Q(A\times B \times (0,t])}\leq K(A\times B \times (0,t]) \qquad \P-\text{ casi seguramente.}   
   \]
\end{itemize}
Como es usual en probabilidad, la dependencia en $\omega$ es omitida en la notación. Cuando dicha medida $K$ existe, decimos que es una \textit{medida dominante} para $M$.
\end{dfn}


\subsection{Definición de la Integral}
En este punto tenemos suficiente teoría para definir la integral de Itô-Walsh con respecto a medidas martingala. Conforme vayamos desarrollando la construcción, vamos a ir notando cierta familiaridad con la construcción de la integral de Lebesgue y la integral de Itô.

\begin{dfn} 
Una función $f:\R^{d}\times [0,\infty)\times \Omega\to \R$ se dice que es \textit{elemental} si es de la forma 
\[
   f(x,t,\omega)=X(\omega)\1_{(a,b]}(t)\1_A(x) 
\]
donde $X$ es una variable aleatoria acotada y $\F_a$-medible, y además $A\in \B(\R^{d})$. 

Definimos la integral de Itô-Walsh para una función elemental de la forma anterior como 

\[
(f\cdot M)_t(B)(\omega):= X(\omega)\left[M_{t\wedge b}(A\cap B)-M_{t\wedge a}(A\cap B)\right](\omega)  
\]
\end{dfn}

Como una primera propiedad, tenemos la siguiente proposición
\begin{prop} 
Sea $f$ una función elemental y $M$ una medida martingala. Entonces $(f\cdot M)$ es nuevamente una medida martingala. En particular, la integral de funciones elementales con respecto a martingalas se vuelve una forma de construir nuevas medidas martingala.
\end{prop}
\begin{proof} 
 Pendiente 
\end{proof}
\begin{ejem} 
Sea $\W$ un ruido blanco en $\R^{d}\times[0,\infty)$ y consideremos a $(W_t(A))_{t\geq0,A\in \B(\R^d)}$ el proceso de ruido blanco. Ya vimos que dicho proceso forma una medida martingala. Sea $f$ una función elemental. Entonces $(f\cdot W)$ es una medida martingala.
\end{ejem}

El siguiente paso en la construcción de la integral es extender la definición a funciones simples. 

\begin{dfn} 
   Decimos que una función $f$ es una función simple si existen $c_1,...,c_n$ constantes reales, y $f_1,...,f_n$ funciones elementales, tales que 
   \[
     f=\sum_{k=1}^{n}c_kf_k.  
   \] Denotaremos por $\mathscr{S}$ el conjunto de las funciones simples. Definimos la integral de Itô-Walsh para funciones simples como 
   \[
   (f\cdot M)_t(B):=\sum_{j=1}^{k}c_j(f_j\cdot M)_t(B)    
   \]
 \end{dfn}
 \begin{prop} 
  La definición anterior es consistente, esto es, no depende de la representación de $f$ en términos de funciones simples.
  \end{prop}
Resulta ser que una clase adecuada de funciones integradoras son las funciones $f$ que son predecibles. Esto es, aquella $\sigma$-álgebra que es generada por todas las funciones simples. Dicha $\sigma$-álgebra la denotamos por $\mathscr{P}$

En este punto, deseamos extender la definición de la integral para funciones más generales, definidas sobre conjuntos no necesariamente rectangulares. Es en este punto en donde entra en juego la función $Q$.  Dicha función es crucial, según se ve en el siguiente 

\begin{prop} 
Sea $f\in \mathscr{S}$ y supongamos que $M$ es una medida martingala digna. Entonces 
\[
\E\left[((f\cdot M)_t(B))^2\right]=\E\left[\int_{B\times B\times (0,t]}f(x,t)f(y,t)Q(dx,dy,dt)\right].   
\]
\end{prop}

\begin{proof} 
   Primero debemos de hacer la demostración para funciones elementales, y posteriormente para funciones simples.
 \end{proof}
Nótese en la proposición anterior que estamos integrando sobre un rectángulo del estilo $B\times B\times (0,t]$, y la idea es extender la integral a regiones más generales. Para ello, necesitamos extender la definición de $Q$ a dichas regiones, tarea que como anticipamos antes, es posible gracias al concepto de martingala digna.

De hecho, si $M$ es una martingala digna, $Q_M$ puede ser extendida a una medida en todo $\B(\R^{d})\times \B^{\R^{d}}\times [0,\infty)$. 

\begin{ejem} 
Sea $\W$ un ruido blanco en $\R^{d}\times[0,\infty)$ y consideremos al proceso de ruido blanco asociado al mismo. Entonces dicho proceso forma una medida martingala digna con medida dominante $K(A\times B \times C):=\lambda^{d}(A\cap B)\lambda(C)$.
\end{ejem}

Tenemos a continuación una proposición con respecto a las medidas martingala dignas y la integral de Itô-Walsh de funciones simples.

\begin{prop} 
Sea $M$ una medida martingala digna y $f$ una función simple. Entonces $(f\cdot M)$ es una medida martingala digna. 
Mas aún, si $Q_N$ y $K_N$ representan al funcional de covarianza y a la medida dominante de una medida martingala digna $N$, entonces 
\begin{align*}
   &Q_{f\cdot M}(dx \ dy \ dz)=f(x,t)f(y,t)Q_M(dx \ dy \ dt)\\
   &K_{f\cdot M}(dx \ dy \ dt)=\abs{f(x,t)f(y,t)}K_M(dx \ dy \ dt). 
\end{align*}
\end{prop}
\begin{proof} 
  La prueba nuevamente va primero por funciones elementales y luego por funciones simples. 
 \end{proof}

A partir de ahora, solo estaremos interesados en el caso cuando la variable temporal está en algún intervalo finito $(0,T]$. Siguiendo la maquinaria estándar para definir nuevos objetos a partir de aproximaciones, definimos ahora una norma apropiada para dicho propósito.

\begin{dfn} 
Sea $M$ una medida martingala digna. Supongamos que $K_M$ es su medida dominante. Sea $f\in \mathscr{P}$ una función en el conjunto de las funciones que son predecibles (es decir, que son medibles con respecto a la $\sigma$-álgebra $\mathscr{P}$ generada por las funciones simples). Definimos la norma $\norm{\cdot}_M$ como sigue 

\end{dfn}
\[
   \norm{f}_M^2:=\E\left[\int_{\R^{d}\times\R^{d}\times (0,T]} \abs{f(x,t)f(y,t)}K_M(dx \ dy \ dt)\right]
\]

Observamos que dicha norma está bien definida. Denotamos por $\mathscr{P}_M$ al conjunto de todas las funciones $f$ predecibles tales que $\E\left[\norm{f}_M\right]<\infty$.

\begin{prop} 
La norma anteriormente definida en efecto es una norma, y el conjunto $\mathscr{P}_M$ es completo con esta norma.
\end{prop}
\begin{proof} 
  pendiente 
 \end{proof}
A continuación un resultado esencial de aproximación, el cual se remite directamente a \cite{Walsh_J.B_Introduction_to_SPDEs} para su demostración.

\begin{teo} 
El conjunto $\mathscr{S}$ es denso en $\mathscr{P}_M$.
\end{teo}
Lo anterior junto con la proposición 5.18 (referenciar) nos dice que 
\[
\E\left[(f\cdot M)_t^{2}(B)\right]\leq \norm{f}_M^2,\qquad \text{ para } t\in (0,T], f\in \mathscr{S}, B\in \B(\R^d).
\]
Luego, gracias a la cota anterior, si $(f_m)_{m\geq1}$ es una sucesión de Cauchy en $(\mathscr{S},\norm{\cdot}_M)$, entonces la sucesión $\left((f_m\cdot M)_t(B)\right)_{m\geq1}$ es una sucesión de Cauchy en $L^{2}(\P)$. Dado que ambos espacios son completos, se sigue la existencia de objetos en $\mathscr{P}$ y $L^{2}(\P)$, que denotamos por $f$ y $(f\cdot M)_t(B)$ respectivamente, de tal forma que 
\[
f_m\xrightarrow[m\to\infty]{\norm{\cdot}_M}f \quad \ent \quad (f_m\cdot M)_t(B) \xrightarrow[m\to\infty]{L^{2}(\P)} (f\dot M)(B).   
\]

De lo anterior, concluimos con el siguiente teorema.

\begin{teo} 
 Sea $M$ una medida martingala digna. Entonces para cualquier $f\in \mathscr{P}_M$, la integral $(f\cdot M)$ es una medida martingala digna qe satisface la proposición 5.23 (referenciar). Más aún, para cualquier $t\in (0,T]$ y $A,B\in \B(\R^{d})$, 
 \[
 \left\langle (f\cdot M)(A),(f\cdot M)(B)\right\rangle _t= \int_{A\times B\times (0,t]}f(x,s)f(y,s)Q_M(dx \ dy \ ds),
 \]
 y además se tiene la siguiente cota en $L^{2}(\P)$.
 \[
 \E\left[(f\cdot M)^{2}_t(B)\right] \leq \norm{f}_M^{2}.
 \]
 \end{teo}
 De hecho, es posible extender la cota en $L^2(\P)$ a una cota en $L^{p}(\P)$, creando así una desigualdad del tipo Burkholder.
 \begin{teo}[\textbf{Desiguadades de Burkholder}]
  Sea $M$ una medida martingala digna. Entonces para cualquier $p\geq2$ existe una constante $c_p\in (0,\infty)$ tal que para cualquier $f$ predecible y cualquier $t>0$, 
  \[
  \E\left[\abs{(f\cdot M)_t(B)}^p\right]\leq c_p \E\left[\left(\int_{\R^{d}\times \R^{d}\times (0,T]}\abs{f(x,t)f(y,t)}K_M(dx \ dy \ dt)\right)^{p/2}\right] 
  \]
  \end{teo}
  Con esto terminamos la construcción de la integral de Itô-Walsh. Ya nos es posible hablar de integrales con respecto a un ruido blanco $\W$, pues sabemos que este proceso en $\R^{d}\times [0,\infty)$ induce una medida martingala digna, y por lo tanto la noción de integral está bien definida para funciones aleatorias adecuadas. 

\section{Formulación Mild de una SPDE. Existencia y unicidad de las soluciones}
Una vez que tenemos construida la teoría de la integral de Itô-Walsh, podemos pasar darle un significado riguroso a una ecuación diferencial parcial estocástica, así como definir con claridad qué significa resolverla. Como vimos en la introducción del capítulo, la heurística para llegar a un problema en cierto sentido equivalente a aquél que involucra derivadas sigue de cerca las ideas de las soluciones débiles en ecuaciones diferenciales parciales clásicas. Concretamente, el uso de integración por partes para lograr el objetivo es clave. 

Consideremos la ecuación diferencial estocástica formal dada por 
\[
\begin{cases}
   \partial_tu(x,t)=\partial_{xx}u(x,t)+f(u(x,t))\W, & \text{ si } t>0, x\in [0,L]\\
   \partial_xu(0,t)=\partial_xu(L,t)=0, & \text{ si } t>0,\\
   u(x,0)=u_0(x), & \text{ si } x\in [0,L].\\
\end{cases}
\]
donde $\W$ es un ruido blanco con respecto a alguna friltración $(\F_t)_{t\geq0}$, y $u_0:[0,L]\to\R$ es una función determinista, medible y acotada, mientras que $f:\R\to\R$ es una función globalmente Lipschitz y acotada.

Si formalmente multiplicamos el problema por una función $\phi \in C^{\infty}(\R)$ tal que $\phi(0)=\phi(L)=0$ e integramos con respecto al tiempo y posteriormente con respecto al espacio, obtendremos que el problema anterior se puede reformular como 

\begin{align*}
   \int_{0}^{L}u(x,t)\phi(x)dx-\int_{0}^{L}u_0(x)\phi(x)dx&=\int_0^{t}\int_0^{L}\partial_{xx}u(x,s)\phi(x)dxds\\
   &+\int_{0}^{t}\int_{0}^{L}f(u(x,s))\phi(x)W(dx \ ds).    
   \end{align*}
Es destacable que ahora tenemos una ecuación integral estocástica en donde la integral con respecto al ruido blanco cobra total sentido. No obstante, lo anterior aún no puede ser tratado de manera rigurosa, ya que $u$ al ser aleatorio no necesariamente será una función derivable. Por lo tanto, si de manera formal utilizamos integración por partes, al ser $\phi$ una función que se anula en la frontera, la integral de la parcial de $u$ multiplicado por $\phi$ se transforma en
\[
   \int_{0}^{t}\int_{0}^{L}\partial_{xx}u(x,s)\phi(x)dx ds=\int_{0}^{t}\int_{0}^{L}u(x,s)\phi''(x)dx ds,
\]
por lo que sustituyendo la expresión anterior en la reormulación de nuestro problema, obtenemos una ecuación integral estocástica. Tal ecuación integral tiene completo sentido, y dado que es una reformulación de nuestro problema inicial pero que puede tratarse de manera rigurosa, podemos considerar que una manera de resolver nuestro problema inicial, es resolver la reformulación integral anterior. Esta es conocida como la solución mild de nuestro problema anterior.

\begin{dfn} 
Decimos que $u$ es una solución \textit{mild} del problema inicial anterior, si existe un proceso estocástico $u(x,t)$ tal que para cualquier función $\phi\in C^{\infty}([0,L])$, donde $\phi'(0)=\phi'(L)=0$, se tiene la igualdad 

\begin{align*}
   \int_{0}^{L}u(x,t)\phi(x)dx-\int_{0}^{L}u_0(x)\phi(x)dx=\int_{0}^{t}\int_{0}^{L}u(x,s)\phi''(x)dx ds+\int_{0}^{t}\int_{0}^{L}f(u(x,s))\phi(x)W(dx \ ds).  
\end{align*}
\end{dfn}

Es conocida teoría que resuelve la ecuación diferencial estocástica del calor. En particular, se tiene el siguiente resultado.

\begin{teo} 
La ecuación estocástica del calor, con función $f$ Lipschitz y acotada, tiene una única solución $\P$- casi seguramente, que satisface lo siguiente para cualquier $T>0$.
\[
\sup_{0\leq x\leq L}\sup_{0\leq t \leq T}\E\left[\abs{u(x,t)}^2\right]<\infty.   
\]
\end{teo}
Este es el resultado principal del capítulo. Y para su prueba, se requiere el siguiente lema bastante conocido en el ámbito de las ecuaciones diferenciales.

\begin{teo}[\textbf{Lema de Gronwall}] 
Supongamos $\phi_1,\phi_2,...:[0,T]\to[0,+\infty)$ son medibles y no decrecientes. Supongamos también que existe una constante $A\in \R$ tal que para cualquier entero $n\geq1$ y para cualquier $t\in[0,T]$,
\[
\phi_{n+1}(t)\leq A\int_{0}^{t}\phi_n(s)ds.   
\]
Entonces 
\[
\phi_n(t)\leq \phi_1(T)\frac{(At)^{n-1}}{(n-1)!}, \qquad \text{ para cualquier }n\geq1, \text{ y } t\in[0,T].   
\]
\end{teo}
Finalmente, el siguiente teorema nos muestra que no solamente hay existencia y unicidad de las solución a la ecuación estocástica del calor, sino que también existe una modificación continua de la misma.

\begin{teo} 
Sea $\Tilde{u}(x,t)$ la solución única $\P$- casi seguramente de la ecuación estocástica del calor. Entonces existe una modificación $u(x,t)$ de dicha solución cuyas trayectorias son continuas.
\end{teo}

Retomaremos la teoría desarrollada hasta aquí sobre ecuaciones diferenciales parciales estocásticas cuando lleguemos al capítulo 4, en donde estudiamos convergencia de las densidades de los promedios espaciales de la solución a la ecuación estocástica del calor. 